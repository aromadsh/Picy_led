{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a494b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d561e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비출판물 말뭉치 중 mscoco로 사용 안 된 자료 가져오기\n",
    "\n",
    "ms_ko = pd.read_csv('mscoco_kononpup_combined.csv')\n",
    "ko_non = pd.read_csv('korean_nonpup_lines.csv')\n",
    "AI_mid = pd.read_json('AIHUB_ko_nonpup_mid.json', orient = 'table', encoding='utf-8')\n",
    "AI_high = pd.read_json('AIHUB_ko_nonpup_high.json', orient = 'table', encoding='utf-8')\n",
    "del ms_ko[\"Unnamed: 0\"]\n",
    "del ko_non[\"Unnamed: 0\"]\n",
    "rest_ko_non = list(set(ko_non['0']) - set(ms_ko['combined']) - set(AI_mid['ko_nonpup'])-set(AI_high['ko_nonpup']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rest_ko_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIHUB 데이터 가져오기\n",
    "\n",
    "os.chdir('./AIHUB/label')\n",
    "target = os.listdir()\n",
    "target.pop(target.index('.DS_Store'))\n",
    "\n",
    "\n",
    "image_id = []\n",
    "questions = []\n",
    "\n",
    "for name in target:\n",
    "    path = f'./{name}/하_validate_{name}'\n",
    "    im = json.load(open(f'{path}/images.json'))\n",
    "    image = pd.DataFrame(im['images'])\n",
    "\n",
    "    que = json.load(open(f'{path}/question.json'))\n",
    "    question = pd.DataFrame(que['questions'])\n",
    "    \n",
    "    temp = []\n",
    "    before = question['image_id'][0]\n",
    "    \n",
    "    for i, q in zip(question['image_id'], question['question']):\n",
    "        if i == before:\n",
    "            temp.append(q)\n",
    "        \n",
    "        else:\n",
    "            image_id.append(before)\n",
    "            questions.append(\"; \".join(temp))\n",
    "            temp = []\n",
    "            temp.append(q)\n",
    "        \n",
    "        before = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d53366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['image_id'] = image_id\n",
    "df['questions'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc62c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "image_list = []\n",
    "image_id_list = []\n",
    "\n",
    "for name in target:\n",
    "    path = f'./{name}/하_validate_{name}'\n",
    "    im = json.load(open(f'{path}/images.json'))\n",
    "    image = pd.DataFrame(im['images'])\n",
    "\n",
    "    for im, im_id in tqdm(zip(image['image'], image['image_id'])):\n",
    "        image_list.append(im)\n",
    "        image_id_list.append(im_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for df_im_id in tqdm(df['image_id']):\n",
    "    for im, im_id in zip(image_list, image_id_list):\n",
    "        if df_im_id == im_id and im not in images:\n",
    "            images.append(im)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "preprocessed_docs = []\n",
    "\n",
    "for i in tqdm(df['questions']):\n",
    "    token_list = []\n",
    "    for token in mecab.pos(i):\n",
    "        if token[1] in ['NNG','VA+ETM']:\n",
    "            token_list.append(token[0])\n",
    "    preprocessed_docs.append(\" \".join(token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d8e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
    "word2id = defaultdict(lambda : 0)\n",
    "for idx, feature in enumerate(vectorizer.get_feature_names()):\n",
    "    word2id[feature] = idx\n",
    "keywords_AIHUB = []\n",
    "for i, sent in tqdm(enumerate(preprocessed_docs)):\n",
    "    temp = []\n",
    "    for token in sent.split():\n",
    "        matrix = sp_matrix[i, word2id[token]]\n",
    "        if 0.3 <= matrix < 1.0:\n",
    "            temp.append(token)\n",
    "    if len(temp)==0:\n",
    "        keywords_AIHUB.append('none')\n",
    "    else:\n",
    "        keywords_AIHUB.append(\",\".join(temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keywords'] = keywords_AIHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765015ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = list(df['keywords'])\n",
    "ko_nonpup = []\n",
    "\n",
    "for words in tqdm(keywords):\n",
    "    count = 0\n",
    "    \n",
    "    for word in words.split(','):\n",
    "        for sent in rest_ko_non:\n",
    "            if word in sent and sent not in ko_nonpup:\n",
    "                ko_nonpup.append(sent)\n",
    "                count+=1\n",
    "                break\n",
    "        if count == 1:\n",
    "            break\n",
    "    if count == 0:\n",
    "        ko_nonpup.append('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cb723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('data: {}, ko_nonpup: {}'.format(len(df), len(ko_nonpup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_nonpup.count('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b42ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ko_nonpup'] = ko_nonpup\n",
    "df.to_csv('AIHUB_ko_nonpup_low.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d571045",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for index, ko in enumerate(df['ko_nonpup']):\n",
    "    if ko == 'none':\n",
    "        indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(indexes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('AIHUB_ko_nonpup_low.json', orient = 'table', force_ascii = False, index =False,indent = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
